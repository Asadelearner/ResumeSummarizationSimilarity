{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResumeSummarization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28nwwKQi6x1V",
        "outputId": "f7580bbf-8326-40e7-e3b9-f1bcb5e9c078"
      },
      "source": [
        "pip install pdfminer.six"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pdfminer.six\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/f3/4fec7dabe8802ebec46141345bf714cd1fc7d93cb74ddde917e4b6d97d88/pdfminer.six-20201018-py3-none-any.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 2.8MB/s \n",
            "\u001b[?25hCollecting cryptography\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/26/7af637e6a7e87258b963f1731c5982fb31cd507f0d90d91836e446955d02/cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 38.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet; python_version > \"3.0\" in /usr/local/lib/python3.7/dist-packages (from pdfminer.six) (3.0.4)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six) (2.4.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six) (2.20)\n",
            "Installing collected packages: cryptography, pdfminer.six\n",
            "Successfully installed cryptography-3.4.7 pdfminer.six-20201018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEGwtK4D75e1",
        "outputId": "2e4378c1-8ed5-4b33-b108-ea4449558604"
      },
      "source": [
        "pip install docx2txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.7/dist-packages (0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFwfWtrd78w7",
        "outputId": "9a156961-d311-4d61-8bf1-03a829b9da61"
      },
      "source": [
        "pip install nltk;"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzPNx8q4-kWJ",
        "outputId": "f9812ac3-0c4e-40d9-b630-ea7fcc31940f"
      },
      "source": [
        "pip install spacy"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.0.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTcbLi4-8n_q",
        "outputId": "3a240fe7-033e-49b8-b36c-13351568f49a"
      },
      "source": [
        "import docx2txt\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "# Setup\n",
        "!pip install -q wordcloud\n",
        "import wordcloud\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import re\n",
        "import subprocess  # noqa: S404\n",
        "import re\n",
        "\n",
        "from pdfminer.high_level import extract_text\n",
        "import docx2txt\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "import docx2txt\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "import os\n",
        "import spacy\n",
        "import pprint\n",
        "from spacy.matcher import Matcher\n",
        "import multiprocessing as mp\n",
        "import glob\n",
        "import docx2txt\n",
        "# Load files\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "DOC_Qi6NYrCo",
        "outputId": "647cb886-66fd-4426-9bcd-3c9905a27486"
      },
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-485eeafe-7b1b-4da9-b0a4-9f04cab46878\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-485eeafe-7b1b-4da9-b0a4-9f04cab46878\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"asadbaig1\",\"key\":\"575395854de15734d29e433921443ffe\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpZouVeuZDHT",
        "outputId": "bdaf9485-b091-49c6-c317-e463a67ef6ce"
      },
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-2shwgYZd-t",
        "outputId": "a16651ea-126a-4874-c58c-185c7d02c668"
      },
      "source": [
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "ref                                                         title                                              size  lastUpdated          downloadCount  \n",
            "----------------------------------------------------------  ------------------------------------------------  -----  -------------------  -------------  \n",
            "gpreda/reddit-vaccine-myths                                 Reddit Vaccine Myths                              229KB  2021-06-01 11:18:46           6653  \n",
            "crowww/a-large-scale-fish-dataset                           A Large Scale Fish Dataset                          3GB  2021-04-28 17:03:01           3925  \n",
            "imsparsh/musicnet-dataset                                   MusicNet Dataset                                   22GB  2021-02-18 14:12:19           1341  \n",
            "dhruvildave/wikibooks-dataset                               Wikibooks Dataset                                   1GB  2021-02-18 10:08:27           2072  \n",
            "promptcloud/careerbuilder-job-listing-2020                  Careerbuilder Job Listing 2020                     42MB  2021-03-05 06:59:52            950  \n",
            "mathurinache/twitter-edge-nodes                             Twitter Edge Nodes                                342MB  2021-03-08 06:43:04            448  \n",
            "fatiimaezzahra/famous-iconic-women                          Famous Iconic Women                               838MB  2021-02-28 14:56:00            680  \n",
            "alsgroup/end-als                                            End ALS Kaggle Challenge                           12GB  2021-04-08 12:16:37            676  \n",
            "simiotic/github-code-snippets                               GitHub Code Snippets                                7GB  2021-03-03 11:34:39            140  \n",
            "coloradokb/dandelionimages                                  DandelionImages                                     4GB  2021-02-19 20:03:47            393  \n",
            "nickuzmenkov/nih-chest-xrays-tfrecords                      NIH Chest X-rays TFRecords                         11GB  2021-03-09 04:49:23            547  \n",
            "mathurinache/the-lj-speech-dataset                          The LJ Speech Dataset                               3GB  2021-02-15 09:19:54            169  \n",
            "stuartjames/lights                                          LightS: Light Specularity Dataset                  18GB  2021-02-18 14:32:26             64  \n",
            "imsparsh/accentdb-core-extended                             AccentDB - Core & Extended                          6GB  2021-02-17 14:22:54             76  \n",
            "nickuzmenkov/ranzcr-clip-kfold-tfrecords                    RANZCR CLiP KFold TFRecords                         2GB  2021-02-21 13:29:51             82  \n",
            "landrykezebou/lvzhdr-tone-mapping-benchmark-dataset-tmonet  LVZ-HDR Tone Mapping Benchmark Dataset (TMO-Net)   24GB  2021-03-01 05:03:40             84  \n",
            "datasnaek/youtube-new                                       Trending YouTube Video Statistics                 201MB  2019-06-03 00:56:47         141539  \n",
            "zynicide/wine-reviews                                       Wine Reviews                                       51MB  2017-11-27 17:08:04         137673  \n",
            "residentmario/ramen-ratings                                 Ramen Ratings                                      40KB  2018-01-11 16:04:39          23574  \n",
            "datasnaek/chess                                             Chess Game Dataset (Lichess)                        3MB  2017-09-04 03:09:09          18843  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZGsJ-RQZpTv",
        "outputId": "5cae89db-231e-46f0-ffe8-f31a5a807a09"
      },
      "source": [
        "! kaggle datasets download -d palaksood97/resume-dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "resume-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp6WliKbbu0D"
      },
      "source": [
        "! mkdir resume-dataset\n",
        "! unzip resume-dataset.zip -d resume-datasetdf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8kTxHg7fqZr"
      },
      "source": [
        "sw = [\"pron\",\"-PRON-\",\"and\",\"the\",\"with\",\"have\",\"a\",\"be\",\"to\",\"in\",\"will\",\"if\",\"by\",\"into\",\"as\",\"&\",\"of\",\"on\",\"at\",\"is\",\n",
        "              \"for\",\"then\", \"once\", \"here\", \"there\",\"who\" ,\"when\", \"where\", \"why\", \"how\",\"an\",\"i\",\n",
        "              \"about\", \"against\", \"between\", \"through\", \"during\", \"before\", \"after\", \"me\", \"my\", \"myself\", \"we\", \"our\",\n",
        "              \"ours\", \"ourselves\", \"you\", \"you're\", \"you've\",\"from\",\"can\",\"those\",\"but\",\"that\",\"may\",\"over\",\"often\",\"this\",\"them\",\"do\",\"much\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZejcSlzYehbU"
      },
      "source": [
        "def extract_text_from_docx(docx_path):\n",
        "    txt = docx2txt.process(docx_path)\n",
        "    if txt:\n",
        "        return txt.replace('\\t', ' ')\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSpLYlo3c38I"
      },
      "source": [
        "def get_doc_list(files):\n",
        "    doc_list = []\n",
        "    for file in files:\n",
        "        print(file)\n",
        "        st = extract_text_from_docx(file)\n",
        "        doc_list.append(st)\n",
        "    print ('Found %s documents under the dir %s .....'%(len(files),\"/content/resume-dataset/Resumes/\"))\n",
        "    return doc_list\n",
        "\n",
        "    # doc_list \n",
        "file_path = glob.glob(\"/content/resume-dataset/Resumes/*.docx\")\n",
        "documents = get_doc_list(file_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJjQyKZUfO0A"
      },
      "source": [
        "docs_list = []\n",
        "for d in documents:\n",
        "    d_nlp = nlp(d.lower())\n",
        "    t_list = []\n",
        "    for token in d_nlp:\n",
        "        tok_lem = str(token.lemma_)\n",
        "        if (tok_lem not in sw):\n",
        "            t_list.append(tok_lem)\n",
        "    str_ = ' '.join(t_list) \n",
        "    docs_list.append(str_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUfYE4kjgXft",
        "outputId": "39af33f4-81a7-4c4e-f4f7-d274ab27faf6"
      },
      "source": [
        "print(docs_list[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kishore kotapati \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " e - mail : kishore_kotapati@yahoo.com \n",
            "\n",
            "                                                                                          phone : 832 - 906 - 7001 \n",
            "\n",
            " experience summary \n",
            "\n",
            "\n",
            "\n",
            " professional 15 year overall experience 9 + year business analysis . \n",
            "\n",
            "\n",
            "\n",
            " work numerous project sr . business analyst , project manager , consultant , application lead within healthcare , retail , mobile , e - commerce , insurance , manufacturing industry . \n",
            "\n",
            "\n",
            "\n",
            " functional domain experience oracle erp suite : jde enterpriseone oneworld . \n",
            "\n",
            "\n",
            "\n",
            " experience start - up business development – jiffyrides mobile app fudbid e - commerce . \n",
            "\n",
            "\n",
            "\n",
            " business intelligence expertise ibm cognos v7/8/10 , jde bi publisher , insight , logi xml . \n",
            "\n",
            "\n",
            "\n",
            " support front - end application apex , command , trimble ( trimview ) , aggqc labsys . \n",
            "\n",
            "\n",
            "\n",
            " technical functional knowledge erp d&l manufacture module like sale order , order cash ( o2c ) , purchase order , procure pay ( p2p ) , inventory transaction , work order bill material . \n",
            "\n",
            "\n",
            "\n",
            " experience servicenow , edi , vmi , salesforce , otc derivative , visio , business service , peoplesoft , worldsoft , as400 , sql , html , css bmc control m. \n",
            "\n",
            "\n",
            "\n",
            " experience agile , soa – service orient architecture , waterfall sdlc process . \n",
            "\n",
            "  project management overview  \n",
            "\n",
            "\n",
            "\n",
            " recommend strategy , policy , procedure evaluate organization outcome ; identify problem ; evaluate trend ; anticipate requirement . \n",
            "\n",
            " accomplish team result communicate job expectation ; planning , monitoring , appraise job result ; coaching , counseling , discipline employee ; initiate , coordinate , enforce system , policy , procedure . \n",
            "\n",
            " maintain staff recruit , selecting , orienting , train employee ; maintain safe secure work environment ; develop personal growth opportunity . \n",
            "\n",
            " accomplish financial objective forecast requirement ; prepare annual budget ; schedule expenditure ; analyze variance ; initiate corrective action . \n",
            "\n",
            " maintain professional technical knowledge attend educational workshop ; review professional publication ; establish personal network ; benchmarke state - - - art practice ; participate professional society . \n",
            "\n",
            "  academic credential  \n",
            "\n",
            " master computer applications(mca ) university madras , india . \n",
            "\n",
            " bachelor science(b.sc ) computer , electronics mathematics sri venkateswara university , india . \n",
            "\n",
            " professional synopsis \n",
            "\n",
            "\n",
            "\n",
            " boston consulting group ( bcg )                                                                                aug 2017 – jan 2018 \n",
            "\n",
            " role : sr . business analyst \n",
            "\n",
            " location : chicago , il - usa \n",
            "\n",
            " \n",
            "\n",
            "  responsibility : \n",
            "\n",
            "\n",
            "\n",
            " servicenow project implementation module : project , resource , demand , report , knowledge \n",
            "\n",
            " track resource allocation across multiple simultaneous project . \n",
            "\n",
            " plan work - suppose work what ? \n",
            "\n",
            " actual work - what people spend time ? compare resource plan ? \n",
            "\n",
            " project administration : prepare material weekly project portfolio review meeting .  \n",
            "\n",
            " gather update project manager other stakeholder populate servicenow \n",
            "\n",
            " ensure report dashboard preppe prior each meeting \n",
            "\n",
            " document track action item each meeting \n",
            "\n",
            " agile scrum \n",
            "\n",
            " work agile scrum environment core concept ceremony : sprint , story , scrum , etc . \n",
            "\n",
            " experience run daily scrum , manage story backlog , report release progress status \n",
            "\n",
            " requirement management \n",
            "\n",
            "  meet internal customer assess new demand \n",
            "\n",
            "  document business requirement standardized manner \n",
            "\n",
            " excellent communication present leadership position ( director , executive level role ) \n",
            "\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " lafargeholcim ( usa canada )                                                                           oct 2012 – jun 2017 \n",
            "\n",
            " role : sr . business analyst \n",
            "\n",
            " location : chicago , il - usa \n",
            "\n",
            "\n",
            "\n",
            "  responsibility : \n",
            "\n",
            " primary involvement various module erp system jd edward enterpriseone . \n",
            "\n",
            " experience d&l manufacture module like sale order , order cash ( o2c ) , purchase order , procure pay ( p2p ) , inventory transaction , work order bill material . \n",
            "\n",
            " work retail strategy implementation e - commerce project north america offer self - builder small contractor simple easy access lafargeholcim ’s own building solution well wide range other construction material service . \n",
            "\n",
            " apply methodology such agile , scrum , sprint process prepare detailed specification use case statement related documentation . \n",
            "\n",
            " manage various project enhancement project manager ensure complete time , within budget meet design specification , utilize demand process use service now . \n",
            "\n",
            " gather business requirement , develop functional specification ensure successful delivery solution . \n",
            "\n",
            " use visio process mapping analysis provide step - - step user guidance document . \n",
            "\n",
            " participate development , testing rollout activity implementation . \n",
            "\n",
            " fulfill role project management implementation system enhancement request . \n",
            "\n",
            " coordination end user developer regard build cognos report various team like pam , sale marketing , p2 m etc . \n",
            "\n",
            " responsible support resolution application issue raise user or identify process deficiency marketing , sale reporting application all line business country . \n",
            "\n",
            " work other support resource within , offsite support consult staff communicate business requirement coordinate testing , acceptance promotion system enhancement . \n",
            "\n",
            " work oracle ( cloud services ) implement two integrate , host saas solution customize meet program requirement ; all phase date deliver time within budget . \n",
            "\n",
            " work business intelligence tool such cognos 7,8 10 , insight , logixml , vmi edi application . \n",
            "\n",
            " development multiple report use reporting tool call insight various module auto generate auto deliver . \n",
            "\n",
            " maintain ongoing relationship business process owner facilitate cooperation problem resolution .  \n",
            "\n",
            " work various application use soa – service orient architecture process . \n",
            "\n",
            " conduct business process need formulate , define document system requirement , create detailed functional design specification .  \n",
            "\n",
            " assist define requirement , provide estimate demand request ( service now ) . \n",
            "\n",
            " participate provide input template , functional requirement test case scenario . \n",
            "\n",
            " assist define user need change request .  \n",
            "\n",
            " responsible help ensure quality consistency project work , include project approach , standard , procedure , documentation , testing , full transition project . \n",
            "\n",
            " extraordinary associate link business technical need , work closely application manager gather requirement . \n",
            "\n",
            " expertise develop document functional requirement specification ( frd ) , software requirement specification ( srs ) , business requirement document ( brd ) , use - case specification non - functional requirement . \n",
            "\n",
            " use    ms visio    carry out    business use case model       business object modeling    effort develop business architecture rapid control application development . \n",
            "\n",
            " experience all phase    software development life cycle    ( sdlc ) use agile methodology include requirement gather , analysis , design , implementation , testing deployment . \n",
            "\n",
            " streamline project scope document template , replace functional specification set use case    wireframe . \n",
            "\n",
            " participate user acceptance testing ( uat ) testing new system functionality . \n",
            "\n",
            " lead business user effectively test accept system enhancement manage promotion process these enhancement . \n",
            "\n",
            " work fls team support apex , command , trimble ( trimview ) , aggqc labsys maintain strict sla . \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " fudbid inc .                                                                                                               sep 2015 – jan 2018 \n",
            "\n",
            " role : business analyst \n",
            "\n",
            " project : mobile e - commerce app \n",
            "\n",
            " location : chicago , il - usa \n",
            "\n",
            "\n",
            "\n",
            "  responsibility : \n",
            "\n",
            "\n",
            "\n",
            " research variety technology direction \n",
            "\n",
            " manage variety saas platforms ( github , slack , google apps , yesware , buffer , zendesk , medium etc ) \n",
            "\n",
            " implement ecommerce portal customer self - service \n",
            "\n",
            " run daily standup meeting \n",
            "\n",
            " create update ticket agile project management tool \n",
            "\n",
            " maintain crm tool client detail meeting schedule \n",
            "\n",
            " b2b sale via cold calling , door knocking , appointment base etc \n",
            "\n",
            " prepare investor deck , pitch deck \n",
            "\n",
            " manage blog page social medium page - campaign , customer follow - up etc \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " jiffyrides inc .                                                                                                               sep 2013 – nov 2017 \n",
            "\n",
            " role : business analyst \n",
            "\n",
            " project : mobile application \n",
            "\n",
            " location : chicago , il - usa \n",
            "\n",
            "\n",
            "\n",
            "  responsibility : \n",
            "\n",
            "  align technology business vision mobile application \n",
            "\n",
            "  select technology platform use implementation \n",
            "\n",
            "  write detailed functional specification \n",
            "\n",
            "  write architectural spec product \n",
            "\n",
            "  finding hire resource \n",
            "\n",
            "  co - ordinate development team \n",
            "\n",
            "  scrum    master - run daily standup solve blocking    issue \n",
            "\n",
            "  qa - test product / app provide feedback / issue \n",
            "\n",
            "  field triage all client problem \n",
            "\n",
            "  manage social medium communication , ad campaign ( organic pay ) \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " baxter healthcare                                                                                                           apr 2009 – oct 2012 \n",
            "\n",
            " role : business system analyst \n",
            "\n",
            " project : integration service global report ( bi ) \n",
            "\n",
            " location : vernon hills , il - usa \n",
            "\n",
            "\n",
            "\n",
            "  responsibility : \n",
            "\n",
            " upgrade erp system worldsoft jde enterpriseone-8.12 . \n",
            "\n",
            " mdm ( master data management ) , fully customize module . module use manage jde data across globe also sync datum current legacy system worldsoft enterpriseone 8.12 . \n",
            "\n",
            " work distribution module order cash ( o2c ) , procure pay ( p2p ) inventory management . \n",
            "\n",
            " part baxter eservice center project team implement ecommerce website enable customer : • place search order • track shipment • search print invoice • view account summary • search pricing product availability • search allocation balance • run product usage report • backorder inquiry • search browse baxter ’s online catalog \n",
            "\n",
            " global report development project - develop jde report across all module output report go xml use bi publisher . \n",
            "\n",
            " edi mapping jde inbound , jde outbound , export other system . \n",
            "\n",
            " work edis like 850 , 856 , 810 so . \n",
            "\n",
            " provide jde info integration team fill gap . \n",
            "\n",
            " deploy jde object par file . \n",
            "\n",
            " preparation training material provide training offshore team bi publisher . \n",
            "\n",
            " interaction oracle team regard bi publisher . \n",
            "\n",
            " status meeting coordination onsite offshore team . \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " sony pictures entertainment                                                                                          jan 2009 – apr2009 \n",
            "\n",
            " role : business system analyst \n",
            "\n",
            " project : development datum interface \n",
            "\n",
            " location : los angeles , ca - usa \n",
            "\n",
            "\n",
            "\n",
            "  responsibility : \n",
            "\n",
            " onsite / offshore coordination . \n",
            "\n",
            " development jde object . \n",
            "\n",
            " application , report tc development . \n",
            "\n",
            " interaction client weekly status meeting . \n",
            "\n",
            " testing documentation . \n",
            "\n",
            "\n",
            "\n",
            " emersonnetwork power ( stratos )                 may2008 – dec 2008 \n",
            "\n",
            " role : techno - functional consultant \n",
            "\n",
            " project : development support \n",
            "\n",
            " location : chicago , il - usa \n",
            "\n",
            "\n",
            "\n",
            "  responsibility : \n",
            "\n",
            " support jde functional issue . \n",
            "\n",
            " development jde object all module . \n",
            "\n",
            " production support . \n",
            "\n",
            " provide solution ad - hoc query . \n",
            "\n",
            " regular package build deployment . \n",
            "\n",
            " resolve printing issue . \n",
            "\n",
            " explain status activity client weekly status meeting . \n",
            "\n",
            " preparation functional technical specifications document . \n",
            "\n",
            "\n",
            "\n",
            " lafarge                 jan 2008 – 2008 \n",
            "\n",
            " role : technical consultant \n",
            "\n",
            " project : archive / purge – solix \n",
            "\n",
            " location : bangalore , india \n",
            "\n",
            "\n",
            "\n",
            "  responsibility : \n",
            "\n",
            " share jde functional knowledge sale finance module solix team integrate system jde archive / purge \n",
            "\n",
            " provide mapping table use . \n",
            "\n",
            " analyze key field table table relation . \n",
            "\n",
            " develop new ube batch application per client 's requirement order avoid integrity issue . \n",
            "\n",
            " provide functional technical spec object develop . \n",
            "\n",
            " interact client get information purge requirements.using workday , workday mobile application sale force saas software project relate \n",
            "\n",
            "              global hr . \n",
            "\n",
            " emerson ( ridge tool )                           aug 2007 – dec 2007 \n",
            "\n",
            " role : technical consultant \n",
            "\n",
            " project : retrofit upgrade \n",
            "\n",
            " location : bangalore , india \n",
            "\n",
            "\n",
            "\n",
            "  responsibility : \n",
            "\n",
            " retrofit jde object . \n",
            "\n",
            " \" table conversion \" upload datum flat file jde z - file . \n",
            "\n",
            " uploaded datum jde z - file jde master file thru \" interoperability \" . \n",
            "\n",
            " comparison object pd ( production ) environment . \n",
            "\n",
            " assign task team member coordinate get work dead line . \n",
            "\n",
            "\n",
            "\n",
            " weyerhaeuser                                                           march 2007 – july 2007 \n",
            "\n",
            " role : technical consultant \n",
            "\n",
            " project : winchester home \n",
            "\n",
            " location : bangalore , india \n",
            "\n",
            "\n",
            "\n",
            "  responsibility : \n",
            "\n",
            " give offshore post implementation support weyerhaeuser manufacturing finance application include standard jde , custom third party application . \n",
            "\n",
            " assign task team member coordinate get work dead line . \n",
            "\n",
            " develop report base upon spec give third party . \n",
            "\n",
            " interaction third party member onsite coordinator clarify doubt . \n",
            "\n",
            " technical specs preparation analysis , issue solve work close co - ordination till final delivery include preparation test case unit test report . \n",
            "\n",
            "\n",
            "\n",
            " cardinal health inc .                                                              oct 2006 – feb 2007 \n",
            "\n",
            " role : technical consultant \n",
            "\n",
            " project : benefit realization project \n",
            "\n",
            " location : philadelphia , pa , usa \n",
            "\n",
            "\n",
            "\n",
            " responsibilitie : \n",
            "\n",
            " involve all business requirement meeting status meeting > > . \n",
            "\n",
            " give onsite technical support cardinal health ’s benefit realization project , philadelphia division d&l , finance manufacturing application include standard jde , custom third party application . \n",
            "\n",
            " analyze client ’s requirement functional view . \n",
            "\n",
            " development application report per client ’s specification . \n",
            "\n",
            " coordinate offshore developer get object . \n",
            "\n",
            " debug test develop object modify meet client requirement . \n",
            "\n",
            " explain status development client weekly status meeting . \n",
            "\n",
            " preparation technical specification work close co - ordination till final delivery include preparation test case unit test report . \n",
            "\n",
            " testing application promotion object turn . \n",
            "\n",
            " development support give third party tool call dsi . \n",
            "\n",
            "\n",
            "\n",
            " johnson diversey inc .                                                    june 2006 – sep 2006 \n",
            "\n",
            " role : technical consultant \n",
            "\n",
            " project : support \n",
            "\n",
            " location : bangalore , india \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  responsibility : \n",
            "\n",
            " give offshore post implementation support johnson diversey d&l , manufacturing , finance cnc application include standard jde , custom third party application . \n",
            "\n",
            " maintain inbound outbound interface , invoice processing , user profile creation maintenance , application profile security management . \n",
            "\n",
            " support client technical cnc module . \n",
            "\n",
            " give support third party tool like apag demand planner . \n",
            "\n",
            " interact daily onsite coordinator end user know client ’s business process . \n",
            "\n",
            " prepare update smtd . \n",
            "\n",
            " access / preserve document central directory .  \n",
            "\n",
            "\n",
            "\n",
            " oen india limit                                                              jan2005 – june 2006 \n",
            "\n",
            " role : technical cnc consultant \n",
            "\n",
            " project : development implementation \n",
            "\n",
            " location : kochin , india \n",
            "\n",
            "\n",
            "\n",
            "  responsibility : \n",
            "\n",
            "  analyze client ’s requirement . \n",
            "\n",
            "  understanding business process , study analyze workflow design solution . \n",
            "\n",
            "  develop object finance , manufacturing d&l module . \n",
            "\n",
            "  testing debug report application . \n",
            "\n",
            "  direct interaction oracle / peoplesoft customer supportto acquire suggestion / solution . \n",
            "\n",
            "  apply esu asus suggest oracle / peoplesoft customer care . \n",
            "\n",
            "  package building , package deployment product packaging . \n",
            "\n",
            "  technical training knowledge transfer give select client . \n",
            "\n",
            "\n",
            "\n",
            " - one hi - tech system private limit .                                  may2003 – dec 2004 \n",
            "\n",
            " role : programmer \n",
            "\n",
            " project : development – visual basic fox pro \n",
            "\n",
            " location : hyderabad , india \n",
            "\n",
            "\n",
            "\n",
            "  responsibility : \n",
            "\n",
            "  development new program . \n",
            "\n",
            "  customization / modification exist program . \n",
            "\n",
            "  test program meet client ’s quality . \n",
            "\n",
            "  prepare documentation . \n",
            "\n",
            "  track datum database . \n",
            "\n",
            "  coordinate team member .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRLhw1159ezn"
      },
      "source": [
        "import docx2txt\n",
        "# Load files\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex5LlOQZ9RYk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71153f12-f01f-4f1b-972b-3584ac0d618b"
      },
      "source": [
        "# example_01.py\n",
        "\n",
        "from pdfminer.high_level import extract_text\n",
        "\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    return extract_text(pdf_path)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "      candidate_names='/content/Asad_Baig(Resume).pdf'\n",
        "      text = extract_text_from_pdf(candidate_names)\n",
        "      print(text)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MUHAMMAD ASAD BAIG \n",
            "\n",
            "Contact# +92341-3099179 \n",
            "\n",
            "Email Address: asadelearner@gmail.com \n",
            "\n",
            "LinkedIn URL: https://www.linkedin.com/in/asad-baig-41a00413b/    \n",
            "\n",
            "Residential Address: Karachi, Pakistan \n",
            "\n",
            "Technical Skills \n",
            "\n",
            "-Android  -Java  -Kotlin -Kony Visualizer -Kony Fabric  -Kony DBX  -Data Structures  -OOP  -\n",
            "Databases  -Html5 CSS3  - Java script -Git  -Jira   \n",
            "\n",
            "  Tello Talk Inc. \n",
            "\n",
            "              Senior Software Engineer - Android (Oct 2020 – to-date) \n",
            "\n",
            "Experience \n",
            "\n",
            "       Responsibilities: My job responsibilities there are designing new features, collaborating with \n",
            "\n",
            "cross functional teams, testing code, fixing bugs, and improving application efficiency. \n",
            "\n",
            "              Technologies: (Java, Kotlin, Git) \n",
            "\n",
            "  Xpert Digital Pvt Ltd. \n",
            "\n",
            "       Senior Mobile Application Developer (Sep 2019 – Sep 2020) \n",
            "\n",
            "       Responsibilities Convert Wireframes into the application, Design and Develop Application \n",
            "and intégrate with backend and middleware, Develop app on multiple channel like iOS / Android/ \n",
            "Web, Develop End To End Solution, Working as Full Stack Software Developer. \n",
            "\n",
            "       Technologies: (Kony, Java, Kotlin, Git) \n",
            "\n",
            "  Invision Custom Solutions \n",
            "\n",
            "       Android Developer (Aug 2017 – Sep 2019) \n",
            "\n",
            "       Responsibilities: My job responsibilities there are designing new features, collaborating with \n",
            "cross functional teams, testing code, fixing bugs, and improving application efficiency. \n",
            "      Technologies: (Java, Kotlin, Git) \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "\fWorked on many projects over the years. Few of them are mentioned below: \n",
            "\n",
            "Projects \n",
            "\n",
            "  Tello Talk: https://play.google.com/store/apps/details?id=com.udna.tellotalk \n",
            "        Role: Senior Software Engineer (Android) \n",
            "\n",
            "Details:  TelloTalk is Pakistan’s first social media app that not only allows you communicate with \n",
            "your friends/family but also gives you a platform to chat and make new friends. \n",
            "\n",
            "  Silk Bank Mobile App: \n",
            "        Role: Senior Mobile Application Developer (Android/iOS) \n",
            "\n",
            "             Tools: -Kony Fabric, Kony Visualizer \n",
            "\n",
            "Details:  It is basically a Retail Banking app for Silk Bank customers. It includes features like \n",
            "payments, transfers, card management, QR bill payments and etc. \n",
            "\n",
            "  Athletix Training System: https://play.google.com/store/apps/details?id=invision.athletix          \n",
            "\n",
            "Role: Android Developer \n",
            "\n",
            "             Tools: -Camera2 API, media recorder, surface view \n",
            "\n",
            "Details: \n",
            "\n",
            "A comprehensive training system with an emphasizes on proper bio-mechanical movements and \n",
            "neurological conditioning to enhance athletic ability by increase speed, power and proprioception. \n",
            "By developing joint and tendon resilience you become more resistant to injury.. Join AthletiX for \n",
            "your own customized athletic training program to follow step by step. \n",
            "\n",
            "  Odds: https://play.google.com/store/apps/details?id=com.invisionsolutions.odds           \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "This app based on “play and win offers” concept. User play a simple game and can get free      \n",
            "coupons and deals. \n",
            "\n",
            "  Calorie Wiz: https://play.google.com/store/apps/details?id=com.igroup.caloriewiz&hl=en \n",
            "\n",
            "Role: Android Developer \n",
            "\n",
            "      Details: \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "  Role: Android Developer \n",
            "  Tools: -Room DB \n",
            "\n",
            "\fA fitness app that maintains and calculates your daily calories and diet plan. User can also see his   \n",
            "progress charts and monthly achievements in it. \n",
            "\n",
            "Details: \n",
            "\n",
            " \n",
            "\n",
            " MSCS(IBA) \n",
            "\n",
            "Education \n",
            "\n",
            "Masters in Computer Science from Institute of Business Administration                                           -                   \n",
            "(In Progress) \n",
            "\n",
            " BSCS(UOK) \n",
            "\n",
            "Bachelor’s in computer science from University Of Karachi \n",
            "\n",
            " INTERMEDIATE \n",
            "\n",
            "Passed with A grade from DJ Science College, Karachi. \n",
            "\n",
            " MATRICULATION \n",
            "\n",
            "Passed with A+ grade from Usman Public School Campus 2, Karachi. \n",
            "\n",
            "Certifications \n",
            "\n",
            " Mobile Application Development \n",
            "\n",
            "Completed Kony Mobile Application development certification. (2020) \n",
            "\n",
            " Mobile Application Development \n",
            "\n",
            "Completed Mobile application development certification from Sir Syed University (2016) \n",
            "\n",
            " Web Development \n",
            "\n",
            "Completed Web Development module A from Sir Syed University. In web development module A I \n",
            "have learned about HTML5, CSS3 and JavaScript.(2015) \n",
            "\n",
            "2016 \n",
            "\n",
            "2012 \n",
            "\n",
            "2010 \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "\f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsehyRfD_l5q"
      },
      "source": [
        "import re\n",
        "import subprocess  # noqa: S404\n",
        "PHONE_REG = re.compile(r'[\\+\\(]?[0-9][0-9 .\\-\\(\\)]{8,}[0-9]')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zukXraXx-qny"
      },
      "source": [
        "def extract_names(txt):\n",
        "    person_names = []\n",
        "\n",
        "    for sent in nltk.sent_tokenize(txt):\n",
        "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
        "            if hasattr(chunk, 'label') and chunk.label() == 'PERSON':\n",
        "                person_names.append(\n",
        "                    ' '.join(chunk_leave[0] for chunk_leave in chunk.leaves())\n",
        "                )\n",
        "\n",
        "    return person_names\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    names = extract_names(text)\n",
        "\n",
        "def doc_to_text_catdoc(file_path):\n",
        "    try:\n",
        "        process = subprocess.Popen(  # noqa: S607,S603\n",
        "            ['catdoc', '-w', file_path],\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.PIPE,\n",
        "            universal_newlines=True,\n",
        "        )\n",
        "    except (\n",
        "        FileNotFoundError,\n",
        "        ValueError,\n",
        "        subprocess.TimeoutExpired,\n",
        "        subprocess.SubprocessError,\n",
        "    ) as err:\n",
        "        return (None, str(err))\n",
        "    else:\n",
        "        stdout, stderr = process.communicate()\n",
        "\n",
        "    return (stdout.strip(), stderr.strip())\n",
        "\n",
        "\n",
        "def extract_phone_number(resume_text):\n",
        "    phone = re.findall(PHONE_REG, resume_text)\n",
        "\n",
        "    if phone:\n",
        "        number = ''.join(phone[0])\n",
        "\n",
        "        if resume_text.find(number) >= 0 and len(number) < 16:\n",
        "            return number\n",
        "    return None\n",
        "\n",
        "# for i, t in enumerate(docs_list):\n",
        "if __name__ == '__main__':\n",
        "    phone_number = extract_phone_number(text)\n",
        "    #  print(phone_number)   \n",
        "\n",
        "    EMAIL_REG = re.compile(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+')\n",
        "\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    return extract_text(pdf_path)\n",
        "\n",
        "\n",
        "def extract_emails(resume_text):\n",
        "    return re.findall(EMAIL_REG, resume_text)\n",
        "\n",
        "# for i, t in enumerate(docs_list):\n",
        "if __name__ == '__main__':\n",
        "    emails = extract_emails(text)\n",
        "#      print(emails)\n",
        "\n",
        "SKILLS_DB = [\n",
        "    'java',\n",
        "    'kotlin',\n",
        "    'html',\n",
        "    'css',\n",
        "    'javascript',\n",
        "    'android',\n",
        "    'iOS',\n",
        "    'data science',\n",
        "    'datascience',\n",
        "    'designer',\n",
        "    'adobe',\n",
        "    'react',\n",
        "    'java script',\n",
        "    'swift',\n",
        "    'objective c',\n",
        "    'databases',\n",
        "    'server',\n",
        "    'application',\n",
        "    'programming',\n",
        "    'training',\n",
        "    'datastructure',\n",
        "    'data structure',\n",
        "    'testing',\n",
        "    'quality assurance',\n",
        "    'operating system',\n",
        "    'sdlc',\n",
        "    'design patterns',\n",
        "    'support',\n",
        "    'agile scrum',\n",
        "    'scrum',\n",
        "    'java',\n",
        "    'business analyst',\n",
        "    'mobile'\n",
        "]\n",
        "\n",
        "\n",
        "def extract_text_from_docx(docx_path):\n",
        "    txt = docx2txt.process(docx_path)\n",
        "    if txt:\n",
        "        return txt.replace('\\t', ' ')\n",
        "    return None\n",
        "\n",
        "\n",
        "def extract_skills(input_text):\n",
        "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "    word_tokens = nltk.tokenize.word_tokenize(input_text)\n",
        "\n",
        "    # remove the stop words\n",
        "    filtered_tokens = [w for w in word_tokens if w not in stop_words]\n",
        "\n",
        "    # remove the punctuation\n",
        "    filtered_tokens = [w for w in word_tokens if w.isalpha()]\n",
        "\n",
        "    # generate bigrams and trigrams (such as artificial intelligence)\n",
        "    bigrams_trigrams = list(map(' '.join, nltk.everygrams(filtered_tokens, 1, 2)))\n",
        "    # print(bigrams_trigrams)\n",
        "    # we create a set to keep the results in.\n",
        "    found_skills = set()\n",
        "\n",
        "    # we search for each token in our skills database\n",
        "    for token in filtered_tokens:\n",
        "        if token.lower() in SKILLS_DB:\n",
        "            found_skills.add(token)\n",
        "\n",
        "    # we search for each bigram and trigram in our skills database\n",
        "    for ngram in bigrams_trigrams:\n",
        "        if ngram.lower() in SKILLS_DB:\n",
        "            found_skills.add(ngram)\n",
        "\n",
        "    return found_skills\n",
        "\n",
        "# for i, t in enumerate(docs_list):\n",
        "if __name__ == '__main__':\n",
        "    #  text = extract_text_from_docx('resume.docx')\n",
        "    skills = extract_skills(text)\n",
        "#     print(skills)  \n",
        "\n",
        "\n",
        "\n",
        "RESERVED_WORDS = [\n",
        "    'school',\n",
        "    'college',\n",
        "    'univers',\n",
        "    'academy',\n",
        "    'faculty',\n",
        "    'institute',\n",
        "    'faculdades',\n",
        "    'Schola',\n",
        "    'schule',\n",
        "    'lise',\n",
        "    'lyceum',\n",
        "    'lycee',\n",
        "    'polytechnic',\n",
        "    'kolej',\n",
        "    'ünivers',\n",
        "    'okul',\n",
        "    'education',\n",
        "    'certications',\n",
        "    'training',\n",
        "    'certifications',\n",
        "    'university',\n",
        "    'BE','B.E.', 'B.E', 'BS', 'B.S', 'ME', 'M.E', 'M.E.', 'MS', 'M.S', 'BTECH', 'MTECH', \n",
        "                    'SSC', 'HSC', 'CBSE', 'ICSE', 'X', 'XII'\n",
        "]\n",
        "\n",
        "\n",
        "def extract_text_from_docx(docx_path):\n",
        "    txt = docx2txt.process(docx_path)\n",
        "    if txt:\n",
        "        return txt.replace('\\t', ' ')\n",
        "    return None\n",
        "\n",
        "\n",
        "def extract_education(input_text):\n",
        "    organizations = []\n",
        "\n",
        "    # first get all the organization names using nltk\n",
        "    for sent in nltk.sent_tokenize(input_text):\n",
        "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
        "            if hasattr(chunk, 'label') and chunk.label() == 'ORGANIZATION':\n",
        "                organizations.append(' '.join(c[0] for c in chunk.leaves()))\n",
        "\n",
        "    # we search for each bigram and trigram for reserved words\n",
        "    # (college, university etc...)\n",
        "    education = set()\n",
        "    for org in organizations:\n",
        "        for word in RESERVED_WORDS:\n",
        "            if org.lower().find(word) >= 0:\n",
        "                education.add(org)\n",
        "\n",
        "    return education\n",
        "\n",
        "# for i, t in enumerate(docs_list):\n",
        "if __name__ == '__main__':\n",
        "#     # text = extract_text_from_docx('resume.docx')\n",
        "    education_information = extract_education(text)\n",
        "#    print(education_information)  \n",
        "# for i, t in enumerate(docs_list):\n",
        "#   if __name__ == '__main__':\n",
        "# person_names = extract_names(t)\n",
        "# phone_number = extract_phone_number(t)   \n",
        "# emails = extract_emails(t)\n",
        "# skills = extract_skills(t)\n",
        "# education_information = extract_education(t)\n",
        "# print(phone_number)\n",
        "# print(emails[0])  \n",
        "# print(skills)\n",
        "# print(education_information)  "
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCKB4sKlBEpI"
      },
      "source": [
        "def find_between(s, start, end):\n",
        "  return (s.split(start))[1].split(end)[0]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  candidate =find_between(candidate_names,\"/content/\",\"(Resume).pdf\")"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mXp-q57_xfg",
        "outputId": "1ca0d9bb-1e9a-4fca-af18-28fd01e00f7e"
      },
      "source": [
        "print(\"Candidates Name: \"+candidate)\n",
        "print(\"Candidates Phone number: \"+phone_number)\n",
        "print(\"Candidates Email id: \" + emails[0])  \n",
        "print(\"Candidates Skill Set: \" )\n",
        "print(skills)\n",
        "print(\"Candidates Education Information: \")\n",
        "print(education_information)         "
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Candidates Name: Asad_Baig\n",
            "Candidates Phone number: +92341-3099179\n",
            "Candidates Email id: asadelearner@gmail.com\n",
            "Candidates Skill Set: \n",
            "{'Android', 'testing', 'Application', 'application', 'Mobile', 'Kotlin', 'training', 'Databases', 'JavaScript', 'Training', 'Java', 'Java script'}\n",
            "Candidates Education Information: \n",
            "{'DJ Science College', 'Institute', 'University Of Karachi'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EcJ-r0dSjoF"
      },
      "source": [
        "def extract_text_from_docx(docx_path):\n",
        "    txt = docx2txt.process(docx_path)\n",
        "    if txt:\n",
        "        return txt.replace('\\t', ' ')\n",
        "    return None\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  resume = extract_text_from_docx('/content/Asad_Baig(Resume).docx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOTOIcKiA7I3",
        "outputId": "e712fa78-c824-4db7-ba58-f47860d03f3e"
      },
      "source": [
        "job_description = docx2txt.process(\"pythonSampleJobDescription.docx\")\n",
        "print(job_description)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python Developer Responsibilities Include:\n",
            "\n",
            "Writing effective, scalable code\n",
            "\n",
            "Developing back-end components to improve responsiveness and overall performance\n",
            "\n",
            "Integrating user-facing elements into applications\n",
            "\n",
            "Job Brief\n",
            "\n",
            "\n",
            "\n",
            "We are looking for a Python Developer to join our engineering team and help us develop and maintain various software products.\n",
            "\n",
            "Python Developer responsibilities include writing and testing code, debugging programs and integrating applications with third-party web services. To be successful in this role, you should have experience using server-side logic and work well in a team.\n",
            "\n",
            "Ultimately, you’ll build highly responsive web applications that align with our business needs.\n",
            "\n",
            "Responsibilities\n",
            "\n",
            "Write effective, scalable code\n",
            "\n",
            "Develop back-end components to improve responsiveness and overall performance\n",
            "\n",
            "Integrate user-facing elements into applications\n",
            "\n",
            "Test and debug programs\n",
            "\n",
            "Improve functionality of existing systems\n",
            "\n",
            "Implement security and data protection solutions\n",
            "\n",
            "Assess and prioritize feature requests\n",
            "\n",
            "Coordinate with internal teams to understand user requirements and provide technical solutions\n",
            "\n",
            "Requirements\n",
            "\n",
            "Work experience as a Python Developer\n",
            "\n",
            "Expertise in at least one popular Python framework (like Django, Flask or Pyramid)\n",
            "\n",
            "Knowledge of object-relational mapping (ORM)\n",
            "\n",
            "Familiarity with front-end technologies (like JavaScript and HTML5)\n",
            "\n",
            "Team spirit\n",
            "\n",
            "Good problem-solving skills\n",
            "\n",
            "BSc in Computer Science, Engineering or relevant field\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDUNJWSTHmYY"
      },
      "source": [
        "text2 = [resume, job_description]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhucX-woIKji"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "count_matrix = cv.fit_transform(text2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCy2PTWgH_Kl",
        "outputId": "cce616a2-8a47-4237-e905-355ae7d47a94"
      },
      "source": [
        "# Get match percentage\n",
        "matchPercentage = cosine_similarity(count_matrix)[0][1] * 100\n",
        "matchPercentage = round(matchPercentage)\n",
        "print(\"Your resume matches about \" + str(matchPercentage) + \"% of the job description.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your resume matches about 43% of the job description.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}